---
title: "TPQ_R_Python"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = TRUE, cache=FALSE}
options(device = "X11")

library(reticulate)
if (dir.exists("/home/abdulrahman/anaconda3/envs/mne/bin/")){
  use_python ("/home/abdulrahman/anaconda3/envs/mne/bin/python3")
}else{
  use_python("/home/asawalma/anaconda3/envs/mne/bin/python3")
  #use_python("/home/asawalma/anaconda3/bin/python")
}

```

```{python Load all data, include = TRUE}
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt


def prepare_icasso(npz_tpq_path):
    """
    prepare the data from the npz files sent to me by Juergen.
    It creates the following five data frames/groups of data frames:
    data_tpq, data_reco, scores, projections and sources
    All DFs will have column names indicating what they represent
    :param npz_tpq_path: the path to the tpq npz (which is the one that contains the basic info such as IDs)
    :return: five data frames (see description)
    """
    npz_tpq = np.load(npz_tpq_path, allow_pickle=True)
    results_path = npz_tpq_path.replace("icasso_ICA-tpq","icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")
    npz_results = np.load(results_path, allow_pickle=True)
    # extract IDs
    IDs = npz_tpq["IDs"]
    diagnoses = []
    trauma = []
    gad = []
    response = []
    ptsd = []
    mdd = []
    session = []
    for i in range(len(IDs)):
        if IDs[i] in list(or_scores["Final ID"]):
            diagnoses.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "Diagnosis"])[0])
            trauma.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "Trauma"])[0])
            gad.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "GAD"])[0])
            response.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "Response"])[0])
            ptsd.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "PTSD"])[0])
            mdd.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "MDD"])[0])
            session.append(list(or_scores.loc[or_scores["Final ID"]==IDs[i], "Session"])[0])
        else:
            diagnoses.append("NA")
            trauma.append("NA")
            gad.append("NA")
            response.append("NA")
            ptsd.append("NA")
            mdd.append("NA")
            session.append("NA")
    # create two data frames to be added to the data inside each dictionary item
    sub_info_2d = [[IDs[i],diagnoses[i],trauma[i], gad[i], response[i], ptsd[i], mdd[i], session[i]] for i in range(len(IDs))]
    sub_info_3d = [sub_info_2d]*npz_results["data_reco"].shape[0]
    sub_info = pd.DataFrame(sub_info_2d, columns=["ID","Diagnosies","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"])
    # read all data
    data_tpq = pd.DataFrame(npz_tpq["data_tpq"])
    data_tpq[["ID","Diagnosis","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"]] = sub_info
    # rename the columns
    data_tpq.columns = ["Q"+str(i) for i in range(1,101)]+["ID","Diagnosis","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"]
    # rearrange the columns, just for aesthetics
    new_colnames = ["ID","Diagnosis","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"] + ["Q"+str(i) for i in range(1,101)]
    data_tpq = data_tpq[new_colnames]
    data_reco = npz_results["data_reco"]
    data_reco = [pd.DataFrame(item, columns=new_colnames) for item in np.append(np.array(sub_info_3d),data_reco,axis = 2)]
    scores = npz_results["scores"]
    projections = npz_results['projection']
    projections = pd.DataFrame(np.append(np.array(sub_info_2d),projections,axis = 1))
    projections.columns = ["ID", "Diagnosis","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"] + ["IC" + str(i) for i in range(1, len(projections.columns) - 7)]
    sources = npz_results["sources"]
    sources = pd.DataFrame(sources, columns = ["Q"+str(i) for i in range(1,101)])
    return(data_tpq, data_reco, scores,projections,sources)
  
# use the scores file to extract diagnoses
scores_path = "/home/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive/PhD/Data/Palestine/TPQ_DataAndAnalysis/TPQ_Analysis_All_25.11.2020_modified.xlsx"
if not os.path.exists(scores_path):
  scores_path = scores_path.replace("/abdulrahman/abdulrahman.sawalma@gmail.com","/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive")
or_scores = pd.read_excel(scores_path)[["Diagnosis","Final ID","Trauma", "GAD", "Response", "PTSD", "MDD", "Session"]]
or_scores.loc[pd.isna(or_scores["Trauma"]),or_scores.columns=="Trauma"] = "NA"
or_scores.loc[pd.isna(or_scores["GAD"]),or_scores.columns=="GAD"] = "NA"
or_scores.loc[pd.isna(or_scores["Response"]),or_scores.columns=="Response"] = "NA"
or_scores.loc[pd.isna(or_scores["PTSD"]),or_scores.columns=="PTSD"] = "NA"
or_scores.loc[pd.isna(or_scores["MDD"]),or_scores.columns=="MDD"] = "NA"

path = '/home/abdulrahman/abdulrahman.sawalma@gmail.com/PhD/Data/Palestine/ICASSO_fixed/decomp_tpq'
if not os.path.exists(path):
    path = path.replace("/abdulrahman/abdulrahman.sawalma@gmail.com","/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive")
    
all_path = path+'/HC,MDD,PTSD,TNP,GAD/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_MNEinfomax.npz'
all_fast_path = path + '/HC,MDD,PTSD,TNP,GAD_FastICA_MNE/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_MNEfastica.npz'
all_fastsk_path = path + '/HC,MDD,PTSD,TNP,GAD_FastICA_sklearn/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_SklearnFastICA.npz'
hc_path  = path + '/HC/icasso_ICA-tpq_HC_nsamp1202_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'
mdd_path = path + '/MDD/icasso_ICA-tpq_MDD_nsamp455_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'
gad_path = path + '/GAD/icasso_ICA-tpq_GAD_nsamp30_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'
ptsd_path = path + '/PTSD/icasso_ICA-tpq_PTSD_nsamp57_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'
tnp_path = path + '/TNP/icasso_ICA-tpq_TNP_nsamp78_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'
disorders_path = path + '/MDD,PTSD,TNP,GAD/icasso_ICA-tpq_MDD,PTSD,TNP,GAD_nsamp620_n_comp13_n_iter100_dist0.30_MNEinfomax.npz'

data_tpq_all, data_reco_all, scores_all,projections_all,sources_all = prepare_icasso(all_path)
data_tpq_all_fast, data_reco_all_fast, scores_all_fast, projections_all_fast, sources_all_fast = prepare_icasso(all_fast_path)
data_tpq_all_fastsk, data_reco_all_fastsk, scores_all_fastsk, projections_all_fastsk, sources_all_fastsk = prepare_icasso(all_fastsk_path)
data_tpq_hc, data_reco_hc, scores_hc,projections_hc,sources_hc = prepare_icasso(hc_path)
data_tpq_mdd, data_reco_mdd, scores_mdd,projections_mdd,sources_mdd = prepare_icasso(mdd_path)
data_tpq_gad, data_reco_gad, scores_gad,projections_gad,sources_gad = prepare_icasso(gad_path)
data_tpq_ptsd, data_reco_ptsd, scores_ptsd,projections_ptsd,sources_ptsd = prepare_icasso(ptsd_path)
data_tpq_tnp, data_reco_tnp, scores_tnp,projections_tnp,sources_tnp = prepare_icasso(tnp_path)
data_tpq_disorders, data_reco_disorders, scores_disorders,projections_disorders,sources_disorders = prepare_icasso(disorders_path)

```

```{python add subjects_decomposition}

def prepare_icasso_subjects(npz_sub_path):
    """
    prepare the data from the npz files sent to me by Juergen.
    It creates the following five data frames/groups of data frames:
    data_tpq, data_reco, scores, projections and sources
    All DFs will have column names indicating what they represent
    :param npz_sub_path: the path to the tpq npz (which is the one that contains the basic info such as IDs)
    :return: five data frames (see description)
    """
    npz_sub = np.load(npz_sub_path, allow_pickle=True)
    results_path = npz_sub_path.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects",
                                                                                            "icasso-results_ICA-subjects")
    npz_results = np.load(results_path, allow_pickle=True)
    # extract IDs
    IDs = npz_sub["IDs"]
    diagnoses = []
    trauma = []
    gad = []
    response = []
    ptsd = []
    mdd = []
    session = []
    for i in range(len(IDs)):
        if IDs[i] in list(or_scores["Final ID"]):
            diagnoses.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "Diagnosis"])[0])
            trauma.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "Trauma"])[0])
            gad.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "GAD"])[0])
            response.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "Response"])[0])
            ptsd.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "PTSD"])[0])
            mdd.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "MDD"])[0])
            session.append(list(or_scores.loc[or_scores["Final ID"] == IDs[i], "Session"])[0])
        else:
            diagnoses.append("NA")
            trauma.append("NA")
            gad.append("NA")
            response.append("NA")
            ptsd.append("NA")
            mdd.append("NA")
            session.append("NA")
    # create two data frames to be added to the data inside each dictionary item
    sub_info_2d = [[IDs[i], diagnoses[i], trauma[i], gad[i], response[i], ptsd[i], mdd[i], session[i]] for i in
                   range(len(IDs))]
    sub_info_3d = [np.array(sub_info_2d).transpose().tolist()] * npz_results["data_reco"].shape[0]
    sub_info = pd.DataFrame(sub_info_2d,
                            columns=["ID", "Diagnosies", "Trauma", "GAD", "Response", "PTSD", "MDD", "Session"]).transpose()
    # read all data
    data_tpq = pd.DataFrame(npz_sub["data_tpq"])
    data_tpq = sub_info.append(data_tpq)
    # rename the columns
    data_tpq.columns = ["S" + str(i) for i in range(1, 1823)]

    data_reco = npz_results["data_reco"]
    data_reco = [pd.DataFrame(item, columns=["S" + str(i) for i in range(1, 1823)]) for item in
                 np.append(np.array(sub_info_3d), data_reco, axis=1)]
    scores = npz_results["scores"]
    projections = npz_results['projection']

    sources = npz_results["sources"]
    sources = pd.DataFrame(np.append(np.array(sub_info_2d).transpose(),sources,axis=0), columns=["S" + str(i) for i in range(1, 1823)])
    return (data_tpq, data_reco, scores, projections, sources)

#Now we add the subjects decomposition
subjects_path = path + "/../../Subject_DataAnalysis/HC,MDD,PTSD,TNP,GAD/n_comp13/icasso_ICA-subjects_HC,MDD,PTSD,TNP,GAD_nsamp100_n_comp13_n_iter100_dist0.40_MNEinfomax.npz"
subjects_tpq_all, subjects_reco_all, subjects_all,subjects_all,subjects_all = prepare_icasso_subjects(subjects_path)

```

```{python trial to calculate reconstructed data from Jurgen}
import os
import numpy as np
import pandas as pd

path = '/home/abdulrahman/abdulrahman.sawalma@gmail.com/PhD/Data/Palestine/ICASSO_fixed/decomp_tpq'
if not os.path.exists(path):
    path = path.replace("/abdulrahman/abdulrahman.sawalma@gmail.com",
                        "/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive")

# New code from Juergen to reconstruc the data
npz_sub_path = path + '/HC,MDD,PTSD,TNP,GAD/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_MNEinfomax.npz'
results_path = npz_sub_path.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects",
                                                                                        "icasso-results_ICA-subjects")

npz_sub = np.load(npz_sub_path, allow_pickle=True)
npz_results = np.load(results_path, allow_pickle=True)

icasso = npz_sub['icasso'].item()
data_tpq = npz_sub['data_tpq']
unmixing = icasso.get_centrotype_unmixing()# of shape: [n_cluster, n_chan]

#2) limit the sources to the number of components
n_comp = 10
sources = npz_results['sources']
sources = sources[:n_comp]
unmixing = unmixing[:n_comp]


#3) apply threshold to sources
threshold = np.percentile(abs(sources),25)
picks = np.abs(sources) < threshold
sources[picks] = 0

#4) apply back-tranformation for each source separately
idx_keep = np.arange(unmixing.shape[0])
data_reco_arr = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
for i, ix in enumerate(idx_keep):
    print ('>>> reconstruction of component %d' % (i+1))
    data_reco = np.transpose(icasso.ica2data(sources, unmixing, idx_keep=ix))
    data_reco_arr[i] = data_reco  
    
data_reco_arr = [pd.DataFrame(item) for item in data_reco_arr]

```

```{python to make sure I understand ICA reconstruction, I will use my own code}

# The way MNE calculates sources is as follows:
# 1- apply pre_whitening (the sd of the whole data)
# 2- remove the pca_mean (the means of the channels)
# 3- compute pca_data by applying the dot product for unmixing_matrix by pca_components
# 4- compute the sources by applying the dot product of pca_data by original_data
# Note: this means that the final SD is not 1. Which is somewhat weird. However, in our case
#       there was one subject who answered all answers with yes

# 1) extract the sources and the unmixing matrix from the numpy file
path = '/home/abdulrahman/abdulrahman.sawalma@gmail.com/PhD/Data/Palestine/ICASSO_fixed/decomp_tpq'
if not os.path.exists(path):
    path = path.replace("/abdulrahman/abdulrahman.sawalma@gmail.com",
                        "/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive")

# New code from Juergen to reconstruc the data
npz_sub_path = path + '/HC,MDD,PTSD,TNP,GAD/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_MNEinfomax.npz'
results_path = npz_sub_path.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects",
                                                                                        "icasso-results_ICA-subjects")

npz_sub = np.load(npz_sub_path, allow_pickle=True)
npz_results = np.load(results_path, allow_pickle=True)

icasso = npz_sub['icasso'].item()
data_tpq = npz_sub['data_tpq']
mixing = npz_sub["mixing"]  # or it is the pseudoinverse of the unmixing matrix np.linalg.pinv(npz_sub["unmixing"])

# 2) limit the sources to the number of components
n_comp = 10
data_reco_current_all = [pd.DataFrame(npz_results["data_reco"][i]) for i in range(n_comp)]
sources = npz_results['sources']
sources = sources[:n_comp]
mixing = mixing[:,:n_comp]


# 3) apply threshold to sources
threshold = np.percentile(abs(sources), 25)
picks = np.abs(sources) < threshold
sources[picks] = 0

# 4) calculate the mean and sd of the original data. These are the values used to centering the data for PCA
# First, make a copy of the data so that you do not affect the original one
tpq_transient = data_tpq.copy()

# calculate the standard deviation of the whole dataset, and convert that to an array of shape (n_channels, 1)
# Add [:,None] to make the data into the shape of (n_channels, 1)
or_sd = np.array(mixing.shape[0] * [np.std(tpq_transient)])[:, None]

# apply sd, and take the mean of the resulting data frame
tpq_transient /= or_sd

# find the mean
or_mean = np.average(tpq_transient, axis=1)[:, None]

# 5) apply back-tranformation for each source separately
idx_keep = np.arange(mixing.shape[1])
data_reco_arr_abd = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])


for i, ix in enumerate(idx_keep):
    print ('>>> reconstruction of component %d' % (i+1))
    new_mixing = np.zeros([mixing.shape[0],mixing.shape[1]])
    new_mixing[:,i] = mixing[:,i]
    data_reco = np.dot(sources.T, new_mixing.T)
    data_reco = ((data_reco.T+ or_mean)*or_sd).T
    data_reco_arr_abd[i] = np.transpose(data_reco)

data_reco_arr_abd = [pd.DataFrame(item) for item in data_reco_arr_abd]

```

```{python same as before, but I will use different sources per data frame}

# The way MNE calculates sources is as follows:
# 1- apply pre_whitening (the sd of the whole data)
# 2- remove the pca_mean (the means of the channels)
# 3- compute pca_data by applying the dot product for unmixing_matrix by pca_components
# 4- compute the sources by applying the dot product of pca_data by original_data
# Note: this means that the final SD is not 1. Which is somewhat weird. However, in our case
#       there was one subject who answered all answers with yes

# 1) extract the sources and the unmixing matrix from the numpy file
path = '/home/abdulrahman/abdulrahman.sawalma@gmail.com/PhD/Data/Palestine/ICASSO_fixed/decomp_tpq'
if not os.path.exists(path):
    path = path.replace("/abdulrahman/abdulrahman.sawalma@gmail.com",
                        "/asawalma/Insync/abdulrahman.sawalma@gmail.com/Google Drive")

# New code from Juergen to reconstruc the data
npz_sub_path_all = path + '/HC,MDD,PTSD,TNP,GAD/icasso_ICA-tpq_HC,MDD,PTSD,TNP,GAD_nsamp1822_n_comp13_n_iter100_dist0.40_MNEinfomax.npz'
results_path_all = npz_sub_path_all.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects",
                                                                                        "icasso-results_ICA-subjects")
                                                                                        
npz_sub_all = np.load(npz_sub_path_all, allow_pickle=True)
npz_results_all = np.load(results_path_all, allow_pickle=True)

icasso = npz_sub_all['icasso'].item()
data_tpq = npz_sub_all['data_tpq']
mixing = npz_sub_all["mixing"]  # or it is the pseudoinverse of the unmixing matrix np.linalg.pinv(npz_sub_all["unmixing"])

npz_sub_path_hc = path+ "/HC/icasso_ICA-tpq_HC_nsamp1202_n_comp13_n_iter100_dist0.30_MNEinfomax.npz"
npz_sub_path_mdd = path+ "/MDD/icasso_ICA-tpq_MDD_nsamp455_n_comp13_n_iter100_dist0.30_MNEinfomax.npz"
npz_sub_path_gad = path+ "/GAD/icasso_ICA-tpq_GAD_nsamp30_n_comp13_n_iter100_dist0.30_MNEinfomax.npz"
npz_sub_path_ptsd = path+ "/PTSD/icasso_ICA-tpq_PTSD_nsamp57_n_comp13_n_iter100_dist0.30_MNEinfomax.npz"
npz_sub_path_tnp = path+ "/TNP/icasso_ICA-tpq_TNP_nsamp78_n_comp13_n_iter100_dist0.30_MNEinfomax.npz"

results_path_hc = npz_sub_path_hc.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")
results_path_mdd = npz_sub_path_mdd.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")
results_path_gad = npz_sub_path_gad.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")
results_path_ptsd = npz_sub_path_ptsd.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")
results_path_tnp = npz_sub_path_tnp.replace("icasso_ICA-tpq", "icasso-results_ICA-tpq").replace("icasso_ICA-subjects","icasso-results_ICA-subjects")

npz_sub_hc = np.load(npz_sub_path_hc, allow_pickle=True)
npz_sub_mdd = np.load(npz_sub_path_mdd, allow_pickle=True)
npz_sub_gad = np.load(npz_sub_path_gad, allow_pickle=True)
npz_sub_ptsd = np.load(npz_sub_path_ptsd, allow_pickle=True)
npz_sub_tnp = np.load(npz_sub_path_tnp, allow_pickle=True)

npz_results_hc = np.load(results_path_hc, allow_pickle=True)
npz_results_mdd = np.load(results_path_mdd, allow_pickle=True)
npz_results_gad = np.load(results_path_gad, allow_pickle=True)
npz_results_ptsd = np.load(results_path_ptsd, allow_pickle=True)
npz_results_tnp = np.load(results_path_tnp, allow_pickle=True)

# 2) limit the sources to the number of components
n_comp = 10
data_reco_current_all = [pd.DataFrame(npz_results_all["data_reco"][i]) for i in range(n_comp)]
sources_all = npz_results_all['sources']
sources_hc = npz_results_hc['sources']
sources_mdd = npz_results_mdd['sources']
sources_gad = npz_results_gad['sources']
sources_ptsd = npz_results_ptsd['sources']
sources_tnp = npz_results_tnp['sources']

sources_all = sources_all[:n_comp]
sources_hc = sources_hc[:n_comp]
sources_mdd = sources_mdd[:n_comp]
sources_gad = sources_gad[:n_comp]
sources_ptsd = sources_ptsd[:n_comp]
sources_tnp = sources_tnp[:n_comp]

mixing = mixing[:,:n_comp]


# 3) apply threshold to sources
sources_all[np.abs(sources_all) < np.percentile(abs(sources_all), 25)] = 0
sources_hc[np.abs(sources_hc) < np.percentile(abs(sources_hc), 25)] = 0
sources_mdd[np.abs(sources_mdd) < np.percentile(abs(sources_mdd), 25)] = 0
sources_gad[np.abs(sources_gad) < np.percentile(abs(sources_gad), 25)] = 0
sources_ptsd[np.abs(sources_ptsd) < np.percentile(abs(sources_ptsd), 25)] = 0
sources_tnp[np.abs(sources_tnp) < np.percentile(abs(sources_tnp), 25)] = 0

# 4) calculate the mean and sd of the original data. These are the values used to centering the data for PCA
# First, make a copy of the data so that you do not affect the original one
tpq_transient = data_tpq.copy()

# calculate the standard deviation of the whole dataset, and convert that to an array of shape (n_channels, 1)
# Add [:,None] to make the data into the shape of (n_channels, 1)
or_sd = np.array(mixing.shape[0] * [np.std(tpq_transient)])[:, None]

# apply sd, and take the mean of the resulting data frame
tpq_transient /= or_sd

# find the mean
or_mean = np.average(tpq_transient, axis=1)[:, None]

# 5) apply back-tranformation for each source separately
idx_keep = np.arange(mixing.shape[1])
data_reco_all_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
data_reco_hc_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
data_reco_mdd_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
data_reco_gad_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
data_reco_ptsd_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])
data_reco_tnp_list = np.zeros([len(idx_keep), data_tpq.shape[0], data_tpq.shape[1]])

for i, ix in enumerate(idx_keep):
    print ('>>> reconstruction of component %d' % (i+1))
    new_mixing = np.zeros([mixing.shape[0],mixing.shape[1]])
    new_mixing[:,i] = mixing[:,i]
    data_reco_all_local = np.dot(sources_all.T, new_mixing.T).T
    data_reco_hc_local = np.dot(sources_hc.T, new_mixing.T).T
    data_reco_mdd_local = np.dot(sources_mdd.T, new_mixing.T).T
    data_reco_gad_local = np.dot(sources_gad.T, new_mixing.T).T
    data_reco_ptsd_local = np.dot(sources_ptsd.T, new_mixing.T).T
    data_reco_tnp_local = np.dot(sources_tnp.T, new_mixing.T).T
    
    data_reco_all_list[i] = ((data_reco_all_local+ or_mean)*or_sd)
    data_reco_hc_list[i] = ((data_reco_hc_local+ or_mean)*or_sd)
    data_reco_mdd_list[i] = ((data_reco_mdd_local+ or_mean)*or_sd)
    data_reco_gad_list[i] = ((data_reco_gad_local+ or_mean)*or_sd)
    data_reco_ptsd_list[i] = ((data_reco_ptsd_local+ or_mean)*or_sd)
    data_reco_tnp_list[i] = ((data_reco_tnp_local+ or_mean)*or_sd)
    
data_reco_all_list = [pd.DataFrame(item) for item in data_reco_all_list]
data_reco_hc_list = [pd.DataFrame(item) for item in data_reco_hc_list]
data_reco_mdd_list = [pd.DataFrame(item) for item in data_reco_mdd_list]
data_reco_gad_list = [pd.DataFrame(item) for item in data_reco_gad_list]
data_reco_ptsd_list = [pd.DataFrame(item) for item in data_reco_ptsd_list]
data_reco_tnp_list = [pd.DataFrame(item) for item in data_reco_tnp_list]

```

```{r rconstructing data test}
options("scipen"=100, "digits"=4)

for (i in 1:length(data_reco_all)){
  data_reco_all[[i]] = as.data.frame(apply(py$data_reco_all[[i]][,9:108],2,as.numeric))
}

data_reco_arr = py$data_reco_arr
data_reco_arr_abd = py$data_reco_arr_abd

mean(apply(abs(data_reco_all[[10]] - data_reco_arr_abd[[10]]),2,mean))
mean(apply(abs(data_reco_all[[10]] - data_reco_arr[[10]]),2,mean))

data_reco_arr[[10]]
data_reco_all[[10]]
cor(data_reco_arr[[10]])


```

```{r  measure the main effect of the factors included (Trauma, MDD, GAD, PTSD and Diagnosis)}
library (ppcor)
library(readxl)
library(reshape2)
library(ggplot2)
library(dplyr)
library(Hmisc)
library(corrplot)
library(abind)

data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all

q_data = data.frame(ifelse(abs(sources_all) > apply(abs(sources_all),2,quantile,0.75),10,NA))
q_data$IC = paste0("IC",1:nrow(q_data))
q_data$IC = factor(q_data$IC, levels = paste0("IC",1:nrow(q_data)))

data_tpq_all$Diagnosis[data_tpq_all$Diagnosis=="NA"] = NA
data_tpq_all$Trauma[data_tpq_all$Trauma=="NA"] = NA
data_tpq_all$GAD[data_tpq_all$GAD=="NA"] = NA
data_tpq_all$Response[data_tpq_all$Response=="NA"] = NA
data_tpq_all$PTSD[data_tpq_all$PTSD=="NA"] = NA
data_tpq_all$MDD[data_tpq_all$MDD=="NA"] = NA

data_tpq_all$Diagnosis = factor(data_tpq_all$Diagnosis)
data_tpq_all$Trauma = factor(data_tpq_all$Trauma)
data_tpq_all$GAD = factor(data_tpq_all$GAD)
data_tpq_all$Response = factor(data_tpq_all$Response)
data_tpq_all$PTSD = factor(data_tpq_all$PTSD)
data_tpq_all$MDD = factor(data_tpq_all$MDD)



# makes data frame separated by diagnosis, cols = questions included, rows = Diagnoses
calc_factor <- function(included_df,fac_name){
  included_df[[fac_name]][included_df[[fac_name]]=="NA"]=NA
  included_df[[fac_name]] = factor(included_df[[fac_name]])
  data_frame = data.frame(sapply(levels(included_df[[fac_name]]), function(x) apply(included_df[included_df[[fac_name]] == x,9:ncol(included_df)],2,mean, na.rm = TRUE)))
  names = sapply(levels(included_df[[fac_name]]), function(x) sum(included_df[[fac_name]] == x, na.rm = TRUE))
  colnames(data_frame) = paste0(colnames(data_frame),"(",names,")")
  data_frame$Question =rownames(data_frame)
  return(data_frame)
}


q_data = data.frame(ifelse(abs(sources_all) > apply(abs(sources_all),1,quantile,0.8),1,NA))
q_data$IC = paste0("IC",1:nrow(q_data))
q_data$IC = factor(q_data$IC, levels = paste0("IC",1:nrow(q_data)))

plot_original <- function(data_score_original, IC_num, Factor){
  ic_included = slice(q_data[IC_num,1:100],rep(1:100, each = nrow(data_score_original)))
  data_ic = data_score_original
  data_ic[,paste0("Q",1:100)] = data_ic[,paste0("Q",1:100)]*ic_included
  data_ic = data_ic[,!is.na(data_ic[1,])]
  
  df_factor = melt(calc_factor(data_ic,Factor), id.vars = "Question", variable.name = "Group", value.name = "MeanScore")
  
  g1 = ggplot(df_factor, aes(x=Question, y = MeanScore, group = Group, color = Group))+
    geom_line(size =1.5)+
    TypicalTheme+
    scale_color_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    scale_x_discrete(name = Factor)
  
  data_means = SMeans(df_factor,"MeanScore","Group")
  g2 = ggplot(data_means,aes(x= Group, y= MeanScore, fill = Group))+
    geom_bar(stat="identity")+
    TypicalTheme+
    scale_fill_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    geom_errorbar(aes(ymin = MeanScore-SEM,ymax = MeanScore+SEM), width = 0.15)+
    scale_x_discrete(name = Factor)
    
  return(multiplot(g1,g2))
}

sapply(1:15, function(x) plot_original(data_tpq_all, x, "Diagnosis"), simplify = FALSE)
sapply(1:15, function(x) plot_original(data_tpq_all, x, "Trauma"), simplify = FALSE)
sapply(1:15, function(x) plot_original(data_tpq_all, x, "GAD"), simplify = FALSE)
sapply(1:15, function(x) plot_original(data_tpq_all, x, "Response"), simplify = FALSE)
sapply(1:15, function(x) plot_original(data_tpq_all, x, "PTSD"), simplify = FALSE)


sapply(1:15, function(x) plot_original(data_tpq_all[data_tpq_all$Session=="Test",], x, "Response"), simplify = FALSE)
sapply(1:15, function(x) plot_original(data_tpq_all[data_tpq_all$Session=="Retest",], x, "Response"), simplify = FALSE)

```

```{r plot projections}

plot_proj <- function(Factor){  
  data = projections_all
  data[,9:ncol(data)] = apply(data[,9:ncol(data)],2,as.numeric)
  
  df_factor = melt(calc_factor(data,Factor), id.vars = "Question", variable.name = "Group", value.name = "MeanScore")
  df_factor$IC = factor(df_factor$Question, levels = paste0("IC",1:15))
  g1 = ggplot(df_factor, aes(x=IC, y = MeanScore, group = Group, color = Group))+
    geom_line(size =1.5)+
    TypicalTheme+
    scale_color_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    scale_x_discrete(name = Factor)
  
  data_means = SMeans(df_factor,"MeanScore","Group")
  g2 = ggplot(data_means,aes(x= Group, y= MeanScore, fill = Group))+
    geom_bar(stat="identity")+
    TypicalTheme+
    scale_fill_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    geom_errorbar(aes(ymin = MeanScore-SEM,ymax = MeanScore+SEM), width = 0.15)+
    scale_x_discrete(name = Factor)
    
  return(multiplot(g1,g2))
}    

sapply(c("Diagnosis","Response","Trauma","GAD","Session"), function(x) plot_proj(x), simplify = FALSE)
```

```{r plot reconstructed data}
library(ggplot2)
library(reshape2)

calc_factor <- function(included_df,fac_name){
  included_df[[fac_name]][included_df[[fac_name]]=="NA"]=NA
  included_df[[fac_name]] = factor(included_df[[fac_name]])
  data_frame = data.frame(sapply(levels(included_df[[fac_name]]), function(x) apply(included_df[included_df[[fac_name]] == x,9:ncol(included_df)],2,mean, na.rm = TRUE)))
  names = sapply(levels(included_df[[fac_name]]), function(x) sum(included_df[[fac_name]] == x, na.rm = TRUE))
  colnames(data_frame) = paste0(colnames(data_frame),"(",names,")")
  data_frame$Question =rownames(data_frame)
  return(data_frame)
}



data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all


q_data = data.frame(ifelse(abs(sources_all) > apply(abs(sources_all),1,quantile,0.8),10,NA))
q_data$IC = paste0("IC",1:nrow(q_data))
q_data$IC = factor(q_data$IC, levels = paste0("IC",1:nrow(q_data)))
sources_melted = melt(sources_all[c(1:100)], value.name = "source_value", variable.name = "Question")

q_data_melted = melt(q_data,id.vars = "IC",variable.name = "Question", value.name = "Included")
q_data_melted$source_value = sources_melted$source_value


plot_reco <- function(IC_num,Factor){
  reco_data = data_reco_all[[IC_num]]
  
  # define columns included, which are the id columns and the included questions
  ID_cols = colnames(reco_data)[1:8]
  
  IC_txt = paste0("IC",IC_num)
  inc_questions = as.character(q_data_melted$Question[q_data_melted$IC == IC_txt&!is.na(q_data_melted$Included)])
  
  data = reco_data[,c(ID_cols,inc_questions)]
  data[,9:ncol(data)] = apply(data[,9:ncol(data)],2,as.numeric)
  
  df_factor = melt(calc_factor(data,Factor), id.vars = "Question", variable.name = "Group", value.name = "MeanScore")
    
  g1 = ggplot(df_factor, aes(x=Question, y = MeanScore, group = Group, color = Group))+
    geom_line(size =1.5)+
    TypicalTheme+
    scale_color_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    scale_x_discrete(name = Factor)
  
  data_means = SMeans(df_factor,"MeanScore","Group")
  g2 = ggplot(data_means,aes(x= Group, y= MeanScore, fill = Group))+
    geom_bar(stat="identity")+
    TypicalTheme+
    scale_fill_manual(values =  c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
    geom_errorbar(aes(ymin = MeanScore-SEM,ymax = MeanScore+SEM), width = 0.15)+
    scale_x_discrete(name = Factor)
  
  return(multiplot(g1,g2))

}

sapply(1:10, function(x) plot_reco(x, "MDD"), simplify = FALSE)
sapply(1:10, function(x) plot_reco(x, "Diagnosis"), simplify = FALSE)
sapply(1:10, function(x) plot_reco(x, "PTSD"), simplify = FALSE)
sapply(1:10, function(x) plot_reco(x, "Trauma"), simplify = FALSE)
sapply(1:10, function(x) plot_reco(x, "Response"), simplify = FALSE)
sapply(1:10, function(x) plot_reco(x, "GAD"), simplify = FALSE)

```

```{r look at the how do ICs load on Cloningers }
library(ggplot2)
library(reshape2)

data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all


q_data = data.frame(ifelse(abs(sources_all) > apply(abs(sources_all),1,quantile,0.8),10,NA))
q_data$IC = paste0("IC",1:nrow(q_data))
q_data$IC = factor(q_data$IC, levels = paste0("IC",1:nrow(q_data)))
sources_melted = melt(sources_all[c(1:100)], value.name = "source_value", variable.name = "Question")

q_data_melted = melt(q_data,id.vars = "IC",variable.name = "Question", value.name = "Included")
q_data_melted$source_value = sources_melted$source_value

questions_ic_plot = ggplot(q_data_melted,aes(x=Question, group = IC))+
  geom_bar(mapping = aes(y =Included),stat="identity",fill = "#CC6666")+
  geom_line(mapping = aes(y =source_value),size=1.2)+
  facet_grid(IC~.)+
  TypicalTheme+
  theme(axis.text.x = element_text(angle = 90))


TPQQuestions = list(NS1=paste0("Q",c(2, 4, 9, 11, 40, 43, 85, 93, 96)),
                    NS2=paste0("Q",c(30, 46, 48, 50, 55, 56, 81, 99)),
                    NS3=paste0("Q",c(32, 66, 70, 72, 76, 78, 87)),
                    NS4=paste0("Q",c(13, 16, 21, 22, 24, 28, 35, 60, 62, 65)),
                    HA1=paste0("Q",c(1, 5, 8, 10, 14, 82, 84, 91, 95, 98)),
                    HA2=paste0("Q",c(18, 19, 23, 26, 29, 47, 51)),
                    HA3=paste0("Q",c(33, 37, 38, 42, 44, 89, 100)),
                    HA4=paste0("Q",c(49, 54, 57, 59, 63, 68, 69, 73, 75, 80)),
                    RD1=paste0("Q",c(27, 31, 34, 83, 94)),
                    RD2=paste0("Q",c(39, 41, 45, 52, 53, 77, 79, 92, 97)),
                    RD3=paste0("Q",c(3, 6, 7, 12, 15, 64, 67, 74, 86, 88, 90)),
                    RD4=paste0("Q",c(17, 20, 25, 36, 58)),
                    NS=paste0("Q",c(2, 4, 9, 11, 40, 43, 85, 93, 96, 30, 46, 48, 50, 55, 56, 81, 99, 32, 66, 70, 72, 76, 78, 87, 13, 16, 21, 22, 24, 28, 35, 60, 62, 65)),
                    HA=paste0("Q",c(1, 5, 8, 10, 14, 82, 84, 91, 95, 98, 18, 19, 23, 26, 29, 47, 51, 33, 37, 38, 42, 44, 89, 100, 49, 54, 57, 59, 63, 68, 69, 73, 75, 80)),
                    RD=paste0("Q",c(27, 31, 34, 83, 94, 39, 41, 45, 52, 53, 77, 79, 92, 97, 3, 6, 7, 12, 15, 64, 67, 74, 86, 88, 90, 17, 20, 25, 36, 58)))

# Cloninger_match -> percentage of cloninger questions found in each of the ICs (e.g. how much is the percentage of HA1 questions found in IC1)
# IC_match -> percentage of IC questions found in each of Cloningers scales (e.g. how much is the percentage of IC2 questions found in RD3)
Cloninger_match = data.frame(Cloninger_dim = names(TPQQuestions))
IC_match = data.frame(Cloninger_dim = names(TPQQuestions))

for (i in 1:nrow(sources_all)){
  IC_num = paste0("IC",i)
  questions = as.character(q_data_melted$Question[(!is.na(q_data_melted$Included) & q_data_melted$IC == IC_num)])
  Cloninger_match[IC_num] = sapply(TPQQuestions, function(x) sum(x %in% questions)/length(x))
  IC_match[IC_num] = sapply(TPQQuestions, function(x) sum(x %in% questions)/length(questions))
}

Cloninger_melted = melt(Cloninger_match, id.vars = "Cloninger_dim", value.name = "Match_percentage", variable.name = "IC")
Cloninger_melted$Match_percentage[Cloninger_melted$Match_percentage<0.3] = 0

IC_melted = melt(IC_match, id.vars = "Cloninger_dim", value.name = "Match_percentage", variable.name = "IC")
IC_melted$Match_percentage[IC_melted$Match_percentage<0.3] = 0

Clo_g = ggplot(Cloninger_melted, aes(x = Cloninger_dim, y= Match_percentage, group = IC, color = Cloninger_dim))+
  geom_bar(stat="identity")+
  facet_grid(IC~.)


IC_g = ggplot(IC_melted, aes(x = Cloninger_dim, y= Match_percentage, group = IC, color = Cloninger_dim))+
  geom_bar(stat="identity")+
  facet_grid(IC~.)

IC_g
Clo_g

```

```{r compare MDD to combined data in terms of questions included and correlations}
library (ppcor)
library(readxl)
library(reshape2)
library(ggplot2)
library(dplyr)
library(Hmisc)
library(corrplot)
library(abind)

data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all

data_tpq_mdd = py$data_tpq_mdd
data_reco_mdd = py$data_reco_mdd
scores_mdd = py$scores_mdd
projections_mdd = py$projections_mdd
sources_mdd = py$sources_mdd

#prepare data
projections_mdd$Diagnosis[projections_mdd$Diagnosis=="NA"]=NA
projections_mdd[,9:ncol(projections_mdd)] = as.data.frame(apply(projections_mdd[,9:ncol(projections_mdd)], 2, as.numeric))
projections_mdd[,1:8] = as.data.frame(apply(projections_mdd[,1:8], 2, as.factor))

projections_all = projections_all[projections_all$ID %in% projections_mdd$ID,]
projections_all$Diagnosis[projections_all$Diagnosis=="NA"]=NA
projections_all[,9:ncol(projections_all)] = as.data.frame(apply(projections_all[,9:ncol(projections_all)], 2, as.numeric))
projections_all[,1:8] = as.data.frame(apply(projections_all[,1:8], 2, as.factor))

CorProj = cor(projections_all[,9:ncol(projections_all)], projections_mdd[,9:ncol(projections_mdd)])
CorProj[CorProj<0.7] = 0
print(CorProj)

CorSource = list()
for (i in 1:ncol(sources_all)){
  Cors = sapply(1:nrow(sources_mdd), function(x) cor.test(as.numeric(abs(sources_all[i,][as.numeric(sources_all[i,])>as.numeric(quantile(sources_all[i,],0.5))])), as.numeric(abs(sources_mdd[x,][as.numeric(sources_all[i,])>as.numeric(quantile(sources_all[i,],0.5))])), method = "spearman")$estimate)
  CorSource = append(CorSource,as.vector(Cors))
}

CorSourceMat = matrix(CorSource, nrow = 15)
CorSourceMat[CorSourceMat<0.2&CorSourceMat>-0.2]=0
CorSourceMat[1:13,1:13]
sources_all[1,]
cor(sources_all,sources_mdd)
```

```{r trials}
library (ppcor)
library(readxl)
library(reshape2)
library(ggplot2)
library(dplyr)
library(Hmisc)
library(corrplot)
library(abind)

data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all

q_data = data.frame(ifelse(abs(sources_all) > apply(abs(sources_all),2,quantile,0.75),10,NA))
q_data$IC = paste0("IC",1:nrow(q_data))
q_data$IC = factor(q_data$IC, levels = paste0("IC",1:nrow(q_data)))

data_tpq_all$Diagnosis[data_tpq_all$Diagnosis=="NA"] = NA
data_tpq_all$Trauma[data_tpq_all$Trauma=="NA"] = NA
data_tpq_all$GAD[data_tpq_all$GAD=="NA"] = NA
data_tpq_all$Response[data_tpq_all$Response=="NA"] = NA
data_tpq_all$PTSD[data_tpq_all$PTSD=="NA"] = NA
data_tpq_all$MDD[data_tpq_all$MDD=="NA"] = NA

data_tpq_all$Diagnosis = factor(data_tpq_all$Diagnosis)
data_tpq_all$Trauma = factor(data_tpq_all$Trauma)
data_tpq_all$GAD = factor(data_tpq_all$GAD)
data_tpq_all$Response = factor(data_tpq_all$Response)
data_tpq_all$PTSD = factor(data_tpq_all$PTSD)
data_tpq_all$MDD = factor(data_tpq_all$MDD)

IC_num = 2
Factor = "MDD"
df = data_reco_all[[IC_num]]


IC_txt = paste0("IC",IC_num)
inc_questions = as.character(q_data_melted$Question[q_data_melted$IC == IC_txt&!is.na(q_data_melted$Included)])

reco_data = data_reco_all[[IC_num]]
ID_cols = colnames(reco_data)[1:8]

df = reco_data[,c(ID_cols,inc_questions)]
df[,c(9:ncol(df))] = apply(df[,c(9:ncol(df))], 2,as.numeric)

for (item in c("Diagnosis","Trauma","GAD","Response","PTSD","MDD")){
  df[[item]][df[[item]]=="NA"]=NA
}


#Do the one factor alone
df[[Factor]][df[[Factor]] == "No"]=0
df[[Factor]][df[[Factor]] == "Yes"]=1
df[[Factor]] = as.factor(df[[Factor]])

df = df[!is.na(df[[Factor]]),]

# Do the sum of questions of this IC
df$IC_sum = as.vector(apply(df[,inc_questions],1,sum))

Form = as.formula(paste0(Factor,"~",paste0(inc_questions,collapse = "+")))
Model = step(glm(formula = Form, data = df, family = binomial),direction = "backward")
Model2 = glm(as.formula(paste(Factor,"~IC_sum")), data = df, family=binomial)
summary(Model)
summary(Model2)

LogisticFunction(Model)
LogisticFunction(Model2, plt_type="glm")

# Apparently, most variables are correlated with each other
# lets check this
library(matlib)
Cors = cor(df[,9:ncol(df)])
corrplot(Cors)
pairs(df[,9:ncol(df)], col=as.factor(df$MDD))
#Not cool
```

```{r plot the question loadings and how much they load on each question}
library(Hmisc)
library(reshape2)
library(corrplot)

data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all

data_tpq_all_fast = py$data_tpq_all_fast
data_reco_all_fast = py$data_reco_all_fast
scores_all_fast = py$scores_all_fast
projections_all_fast = py$projections_all_fast
sources_all_fast = py$sources_all_fast


#convert the first 8 columns to factor and the last 100 as numerics for all sub_dataframes in data_reco
for (i in 1:length(data_reco_all)){
  data_reco_all[[i]][,9:ncol(data_reco_all[[i]])] = as.data.frame(apply(data_reco_all[[i]][,9:ncol(data_reco_all[[i]])],2,as.numeric))
  data_reco_all[[i]][,1:8] = as.data.frame(apply(data_reco_all[[i]][,1:8],2,as.factor))
}
for (i in 1:length(data_reco_all_fast)){
  data_reco_all_fast[[i]][,9:ncol(data_reco_all_fast[[i]])] = as.data.frame(apply(data_reco_all_fast[[i]][,9:ncol(data_reco_all_fast[[i]])],2,as.numeric))
  data_reco_all_fast[[i]][,1:8] = as.data.frame(apply(data_reco_all_fast[[i]][,1:8],2,as.factor))
}

df_scores = data_tpq_all

list_loading = sapply(1:length(data_reco_all), function(x) cbind(df_scores[,1:8],(data_reco_all[[1]][,9:108] /df_scores[,9:108])), simplify = FALSE)
list_loading_fast = sapply(1:length(data_reco_all_fast), function(x) cbind(df_scores[,1:8],(data_reco_all_fast[[1]][,9:108] /df_scores[,9:108])), simplify = FALSE)

IC_num = 1
df_loading = list_loading[[IC_num]]
inf_inds = simplifyDims(lapply(1:100, function(x) which(df_loading[,x]==Inf|df_loading[,x]==-Inf)))

df_loading = df_loading[-inf_inds,]

inc_loadings = sapply(9:108, function(x) sum(abs(df_loading[,x]) > 0.25, na.rm = TRUE)>0.4*nrow(df_loading))
inc_loadings_melt = melt(df_loading,id.vars = "ID", measure.vars = paste0("Q",1:100), variable.name = "Question", value.name = "Loading")
fig_loading = ggplot(inc_loadings_melt, aes(x= Question, y = ID))+
    geom_raster(aes(fill=Loading)) + 
    scale_fill_gradient2(high="#CC0000", low="#08457E", mid = "white", midpoint = 0, limits = c(-1,1)) +
    ggtitle(label = "Final Scores for All Subjects", subtitle = "For the 5 Groups of Subjects")

corrplot(cor(data_reco_all[[1]][,9:108]))

corrplot(cor(cbind(data_reco_all[[1]][,9:108],data_reco_all[[3]][,9:108])))

corrplot(cor(cbind(data_reco_all_fast[[1]][,9:108],data_reco_all[[2]][,9:108])))
# All questions inside each IC, and questions of different ICs are very highly correlated

# do the correlation on the subjects
df_1_t = t(data_reco_all[[1]][,9:108])
df_2_t = t(data_reco_all[[2]][,9:108])
df_3_t = t(data_reco_all[[3]][,9:108])

corrplot(cor(cbind(df_1_t[,1:150],df_2_t[,1:150],df_3_t[,1:150])))
# very good, no correlation between different ICs
```

```{r compare different IC methods}
library(ggplot2)
library(reshape2)

calc_factor <- function(included_df,fac_name){
  included_df[[fac_name]][included_df[[fac_name]]=="NA"]=NA
  included_df[[fac_name]] = factor(included_df[[fac_name]])
  data_frame = data.frame(sapply(levels(included_df[[fac_name]]), function(x) apply(included_df[included_df[[fac_name]] == x,9:ncol(included_df)],2,mean, na.rm = TRUE)))
  names = sapply(levels(included_df[[fac_name]]), function(x) sum(included_df[[fac_name]] == x, na.rm = TRUE))
  colnames(data_frame) = paste0(colnames(data_frame),"(",names,")")
  data_frame$Question =rownames(data_frame)
  return(data_frame)
}



data_tpq_all = py$data_tpq_all
data_reco_all = py$data_reco_all
scores_all = py$scores_all
projections_all = py$projections_all
sources_all = py$sources_all



data_tpq_all_fast = py$data_tpq_all_fast
data_reco_all_fast = py$data_reco_all_fast
scores_all_fast = py$scores_all_fast
projections_all_fast = py$projections_all_fast
sources_all_fast = py$sources_all_fast

data_tpq_all_fastsk = py$data_tpq_all_fastsk
data_reco_all_fastsk = py$data_reco_all_fastsk
scores_all_fastsk = py$scores_all_fastsk
projections_all_fastsk = py$projections_all_fastsk
sources_all_fastsk = py$sources_all_fastsk


#convert the first 8 columns to factor and the last 100 as numerics for all sub_dataframes in data_reco
for (i in 1:length(data_reco_all)){
  data_reco_all[[i]][,9:ncol(data_reco_all[[i]])] = as.data.frame(apply(data_reco_all[[i]][,9:ncol(data_reco_all[[i]])],2,as.numeric))
  data_reco_all[[i]][,1:8][data_reco_all[[i]][,1:8] == "NA"]=NA
  data_reco_all[[i]][,1:8] = as.data.frame(apply(data_reco_all[[i]][,1:8],2,as.factor))
}
for (i in 1:length(data_reco_all_fast)){
  data_reco_all_fast[[i]][,9:ncol(data_reco_all_fast[[i]])] = as.data.frame(apply(data_reco_all_fast[[i]][,9:ncol(data_reco_all_fast[[i]])],2,as.numeric))
  data_reco_all_fast[[i]][,1:8][data_reco_all_fast[[i]][,1:8] == "NA"]=NA
  data_reco_all_fast[[i]][,1:8] = as.data.frame(apply(data_reco_all_fast[[i]][,1:8],2,as.factor))
}
for (i in 1:length(data_reco_all_fastsk)){
  data_reco_all_fastsk[[i]][,9:ncol(data_reco_all_fastsk[[i]])] = as.data.frame(apply(data_reco_all_fastsk[[i]][,9:ncol(data_reco_all_fastsk[[i]])],2,as.numeric))
  data_reco_all_fastsk[[i]][,1:8][data_reco_all_fastsk[[i]][,1:8] == "NA"]=NA
  data_reco_all_fastsk[[i]][,1:8] = as.data.frame(apply(data_reco_all_fastsk[[i]][,1:8],2,as.factor))
}




plot_IC_compare <- function(IC_num,Factor, df_1,df_2, data_frame_1_text, data_frame_2_text){
  
  melted_df_1 = melt(df_1, id.vars = c("ID",Factor), measure.vars = paste0("Q",1:100), value.name = "Reconstructed_values", variable.name = "Question")
  melted_df_2 = melt(df_2, id.vars = c("ID",Factor), measure.vars = paste0("Q",1:100), value.name = "Reconstructed_values", variable.name = "Question")
  
  DataMeans_1 = SMeans(melted_df_1,"Reconstructed_values",IVs = c("Question",Factor), GroupBy = Factor)
  DataMeans_2 = SMeans(melted_df_2,"Reconstructed_values",IVs = c("Question",Factor), GroupBy = Factor)
  
  g1 = ggplot(DataMeans_1,aes(x=Question,y = Reconstructed_values, group = Groups, fill = Groups))+
    geom_point(size=2,shape = 21,color = "black")+
    scale_fill_manual(values = c("black","white","#00A550","#Eb4C42","#0087BD"))+
    TypicalTheme+
    ggtitle(paste0(Factor," Groups Compared in IC", IC_num),subtitle = paste0("for ",data_frame_1_text," Data Frame"))
  
  g2 = ggplot(DataMeans_2,aes(x=Question,y = Reconstructed_values, group = Groups, fill = Groups))+
    geom_point(size=2,shape = 21,color = "black")+
    scale_fill_manual(values = c("black","white","#00A550","#Eb4C42","#0087BD"))+
    TypicalTheme+
    ggtitle(paste0(Factor," Groups Compared in IC", IC_num),subtitle = paste0("for ",data_frame_2_text," Data Frame"))
  
  return(list(g1,g2))
}

plot_IC_single <- function(IC_num,Factor, df_1, data_frame_1_text){
  melted_df_1 = melt(df_1, id.vars = c("ID",Factor), measure.vars = paste0("Q",1:100), value.name = "Reconstructed_values", variable.name = "Question")

  DataMeans_1 = SMeans(melted_df_1,"Reconstructed_values",IVs = c("Question",Factor), GroupBy = Factor)
  
  #if you have 3 factor levels (HC, Non-responder and responder), change color order to reflect this
  if (nlevels(df_1[[Factor]])==3){
    Colors = c("#6cBE58","#C33E3B","#4EA3DF","#808CA3","#B9B0AB")
  } else {
    Colors = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB")
  }
  
  g1 = ggplot(DataMeans_1,aes(x=Question,y = Reconstructed_values, group = Groups, fill = Groups))+
    geom_point(size=2,shape = 21,color = "black")+
    scale_fill_manual(values = Colors)+
    TypicalTheme+
    ggtitle(paste0(Factor," Groups Compared in IC", IC_num),subtitle = paste0("for ",data_frame_1_text," Data Frame"))
  return(list(g1))
}

IC_num = 1
Factor = "Trauma"
data_frame_1_text = "Infomax"
data_frame_2_text = "FastICA"
data_frame_3_text = "FastICA_sklearn"
data_list_1 = data_reco_all
data_list_2 = data_reco_all_fast
data_list_3 = data_reco_all_fastsk

df_1 = data_list_1[[IC_num]]
df_2 = data_list_2[[IC_num]]
df_3 = data_list_3[[IC_num]]

gs_infomax = sapply(1:length(data_list_1), function(x) plot_IC_single(x,Factor,data_list_1[[x]], data_frame_1_text))
gs_fast = sapply(1:length(data_list_2), function(x) plot_IC_single(x,Factor,data_list_2[[x]], data_frame_2_text))
gs_fastsk = sapply(1:length(data_list_3), function(x) plot_IC_single(x,Factor,data_list_3[[x]], data_frame_3_text))
#gs = sapply(1:lengthx) plot_IC(IC_num, Factor, df_1, df_2, data_frame_1_text, data_frame_2_text)

multiplot(gs_infomax, Listing = TRUE, cols = 3)


#Now try to find the difference if we include a random variable
# I will make the factor inside Session, just to preserve its order
IC_num = 1
Factor = "Session"
data_frame_4_text = "Infomax"
data_list_4 = data_reco_all
for (i in 1:length(data_list_4)){
  data_list_4[[i]]$Session=factor(paste0("G",c(rep(c(1,2,3,4,5), 364),1,2)))
}

gs_fast = sapply(1:length(data_list_4[1:3]), function(x) plot_IC_single(x,Factor,data_list_4[[x]], data_frame_4_text))
multiplot(gs_infomax, Listing = TRUE, cols = 3)


```

```{r Check subject groups and question groups that contribute to each IC}
library(reshape2)
projections_all = py$projections_all
sources_all = py$sources_all

Factor = "Diagnosis"

# convert projections to numeric
ic_count = ncol(projections_all)-8
projections_all[,9:ncol(projections_all)] = as.data.frame(apply(projections_all[,9:ncol(projections_all)],2,as.numeric))
projections_all[,1:8] = as.data.frame(apply(projections_all[,1:8],2,as.factor))
projections_all[,1:8][projections_all[,1:8] == "NA"] = NA
projections_all$ID = factor(projections_all$ID, levels = projections_all$ID)
projections_melted = melt(projections_all, id.vars = c("ID",Factor), measure.vars = paste0("IC",1:ic_count), value.name = "Projection", variable.name = "IC")


projections_means = SMeans(projections_melted, "Projection", c("IC",Factor), GroupBy = Factor)
projections_means$Projection = abs(projections_means$Projection)
projections_means$IC = factor(projections_means$IC, levels = paste0("IC",1:nlevels(projections_melted$IC)))
for (IC in paste0("IC",1:nlevels(projections_means$IC))){
  projections_means$Max[projections_means$IC==IC] = max(projections_means$Projection[projections_means$IC==IC])
}
projections_means$Max_group = ifelse(projections_means$Max == projections_means$Projection,"*","")

# calculate the difference for each one
for (IC in paste0("IC",1:nlevels(projections_means$IC))){
  for (lvl in levels(factor(projections_means[[Factor]]))){
    projections_means$Difference[projections_means$IC==IC&projections_means[[Factor]]==lvl] = sum(abs(projections_means$Projection[projections_means$IC==IC&projections_means[[Factor]]==lvl] - projections_means$Projection[projections_means$IC==IC&projections_means[[Factor]]!=lvl]))
  }
}

# find the largest difference
for (IC in paste0("IC",1:nlevels(projections_means$IC))){
  projections_means$MDif[projections_means$IC==IC] = max(projections_means$Difference[projections_means$IC==IC])
}

projections_means$RDif = round(projections_means$Difference/projections_means$MDif,2)
projections_means$RDif_text = paste(projections_means[[Factor]]," = ",projections_means$RDif)

# delete those with less than 0.5 difference
projections_means$RDif_text[projections_means$RDif<0.75] = ""
projections_means$Inclusion = ifelse(projections_means$RDif>0.75,"*","")

g1 = ggplot(projections_means, aes(x=Groups, y=Projection, group = Groups, fill = Groups))+
  geom_bar(stat="identity", color = "black")+
  geom_errorbar(aes(ymin = Projection-SEM,ymax = Projection+SEM), width = 0.15)+
  facet_grid(~IC)+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  TypicalTheme+
  geom_text(aes(y = ifelse(projections_means$Projection>0,projections_means$Projection+0.007,projections_means$Projection-0.007),color = Groups, label=Max_group),size =15)+
  scale_color_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  ggtitle("Absolute Values for IC Projections for 5 Groups of Subjects", subtitle = "Stars indicate groups with largest differences")

ggplot(projections_melted, aes(x = ID, y=Projection, group = Diagnosis,color = Diagnosis))+
  geom_point()+
  facet_wrap(~IC)
```

```{r T and F percentage for all questions (Mohammd Binomiality)}
data =  data_tpq_all
data$All = "Yes"
calc_per <- function(Factor){
  ans_true = sapply(9:108,function(x) data[(data[[Factor]]=="Yes"&!is.na(data[[Factor]]=="Yes")),x]==1)
  per_True = apply(ans_true,2,sum)/length(ans_true[,1])
  per_False = 1-per_True
  percentage = data.frame(Question =paste0("Q", 1:100),True = round(100*per_True,1), False = round(100*per_False,2))
  percentage_ar = percentage[order(percentage$True),]
  percentage_ar$Question = gsub("Q","A",percentage_ar$Question)
  percentage = rbind(percentage,percentage_ar)
  percentage$Question = factor(percentage$Question, levels = percentage$Question)
  percentage$Arrangement = rep(c("Normal","Arranged"),each = 100)
  percentage=melt(percentage, id.vars =c("Question", "Arrangement"), variable.name = "Answer", value.name = "Percentage")
  small_data = percentage[(percentage$Arrangement == "Normal" & percentage$Answer == "True"),]
  small_data$Arrangement = NULL
  small_data$Answer = NULL
  small_data$Group = Factor
  
  fig = ggplot(percentage)+
    geom_bar(aes(x=Question, y=Percentage, group = Answer, fill = Answer),stat= "identity")+
    scale_fill_manual(values = c("#808CA3","#B9B0AB"))+
    TypicalTheme+
    ggtitle("Percentage of Subject Answers to TPQ Questions", subtitle = paste0("For ",Factor," Subjects"))+
    theme(axis.text.x = element_text(angle = 90))+
    facet_wrap(~Arrangement,scales = "free",ncol=1)
 
  
  return(list(percentage,small_data, fig))
}
all_true = calc_per("All")
mdd_true = calc_per("MDD")
gad_true = calc_per("GAD")
ptsd_true = calc_per("PTSD")
trauma_true = calc_per("Trauma")

AllData = rbind(all_true[[2]],gad_true[[2]],mdd_true[[2]],ptsd_true[[2]],trauma_true[[2]])

# to improve text on graph, I will create a variable for text position. 
# It will be based on summing the percentage values for that particular question in all Groups (so, the position for "All" group will be the sum of percentages of all other groups ... and so on)
GG = c("All","GAD","MDD","PTSD","Trauma")


for (i in 1:100){
  Question = paste0("Q",i)
  values = AllData$Percentage[AllData$Question==Question] 
  perc = sapply(GG,function(x) round(100*AllData$Percentage[AllData$Group==x&AllData$Question==Question] / sum(AllData$Percentage[AllData$Question==Question]),1))
  norm_pos = sapply(1:length(GG), function(x) sum(values[x:5]))
  perc_pos = sapply(1:length(GG), function(x) sum(perc[x:5]))
  
  AllData$Perc_Percentage[AllData$Question==Question] = perc
  AllData$Perc_Position[AllData$Question==Question] = perc_pos-5
  AllData$T_Position[AllData$Question==Question] = norm_pos-20
}

#The following is for text
norm = ggplot(AllData,aes(x=Question, y=Percentage, group = Group, fill = Group))+
  geom_bar(stat= "identity")+
  TypicalTheme+
  scale_fill_manual(values = c("#6cBE58","#4EA3DF","#C33E3B","#808CA3","#B9B0AB"))+
  ggtitle("Percentage of \"True\" Answers to TPQ Questions")+
  geom_text(aes(y = T_Position,label=Percentage), angle = 90)+
  theme(axis.text.x = element_text(angle = 90))
  

perc = ggplot(AllData,aes(x=Question, y=Perc_Percentage, group = Group, fill = Group))+
  geom_bar(stat= "identity")+
  TypicalTheme+
  scale_fill_manual(values = c("#6cBE58","#4EA3DF","#C33E3B","#808CA3","#B9B0AB"))+
  ggtitle("Percentage of Percentages of Subject Answers to TPQ Questions", subtitle = paste0(" Note: this figure just shows the percentages of the percentages of the figures above"))+
  geom_text(aes(y = Perc_Position,label=Perc_Percentage), angle = 90)+
  theme(axis.text.x = element_text(angle = 90))

multiplot(norm,perc)
```

```{r create a new projection df (from the separate group data_reco and projections) and compare this to the ones obtained from the combianed ICA data frames}
library(reshape2)

prepare_data <- function(local_df){
  # A function to prepare projections data frames
  # 1. remove NAs
  for (i in 1:8){
    local_df[,i][local_df[,i]=="NA"]=NA
  }
  
  # 2. convert the first 8 columns into factors and the rest into doubles
  local_df[,9:ncol(local_df)] = as.data.frame(apply(local_df[,9:ncol(local_df)],2,as.numeric))
  local_df[,2:8] = as.data.frame(apply(local_df[,2:8],2,as.factor))
  local_df[,1] = factor(local_df[,1], levels = local_df[,1])
  
  return (local_df)
}


#data_reco_all = lapply(py$data_reco_all,prepare_data)
projections_all = prepare_data(py$projections_all)
projections_gad = prepare_data(py$projections_gad)
projections_hc = prepare_data(py$projections_hc)
projections_mdd = prepare_data(py$projections_mdd)
projections_ptsd = prepare_data(py$projections_ptsd)
projections_tnp = prepare_data(py$projections_tnp)

sources_all = py$sources_all
sources_GAD = py$sources_gad
sources_HC = py$sources_hc
sources_MDD = py$sources_mdd
sources_PTSD = py$sources_ptsd
sources_TNP = py$sources_tnp

projections_grouped = split(projections_all,projections_all$Diagnosis)


calc_proj_mat <- function(df_group, Factor, max_components=NA){
  df_all = projections_all
  
  # make sure both data frames have the same subjects, and choose the IC columns
  df_all = df_all[df_all$ID %in% df_group$ID,]
  df_group = df_group[df_group$ID %in% df_all$ID,]
  
  df_all = df_all[,9:ncol(df_all)]
  df_group = df_group[,9:ncol(df_group)]
  if (!is.na(max_components)){
    df_all = df_all[,1:max_components]
    df_group = df_group[,1:max_components]
  }
  
  # prepare the matrix and its dimnames
  CorProj = matrix(0,nrow = ncol(df_all), ncol = ncol(df_group))
  dimnames(CorProj) = list(colnames(df_all),colnames(df_group))
  names(dimnames(CorProj)) = c("All",Factor)
  
  for (i in 1:ncol(df_all)){
    p_threshold = 0.05/ncol(df_group) # divide the threshold on the number of comparisons per IC
    p_values = sapply(1:ncol(df_group),function(x) cor.test(df_all[,i],df_group[,x],method = "spearman")$p.value)<p_threshold
    estimates = sapply(1:ncol(df_group),function(x) cor.test(df_all[,i],df_group[,x],method = "spearman")$estimate)
    estimates = round(estimates,2)
    
    # add a star (*) next to significant values
    estimates = ifelse(p_values,estimates,0)
    CorProj[i,] = estimates
  }
  return (CorProj)
}


GAD_proj_mat = calc_proj_mat(projections_gad, "GAD", max_components = 10)
MDD_proj_mat = calc_proj_mat(projections_mdd, "MDD", max_components = 10)
HC_proj_mat = calc_proj_mat(projections_hc, "HC", max_components = 10)
PTSD_proj_mat = calc_proj_mat(projections_ptsd, "PTSD", max_components = 10)
TNP_proj_mat = calc_proj_mat(projections_tnp, "Trauma", max_components = 10)

cor_th = 0.6
GAD_proj_mat[abs(GAD_proj_mat)<cor_th]=0
MDD_proj_mat[abs(MDD_proj_mat)<cor_th]=0
HC_proj_mat[abs(HC_proj_mat)<cor_th]=0
PTSD_proj_mat[abs(PTSD_proj_mat)<cor_th]=0
TNP_proj_mat[abs(TNP_proj_mat)<cor_th]=0

GAD_ICs = rownames(GAD_proj_mat)[apply(abs(GAD_proj_mat),1,max)>0]
MDD_ICs = rownames(MDD_proj_mat)[apply(abs(MDD_proj_mat),1,max)>0]
HC_ICs = rownames(HC_proj_mat)[apply(abs(HC_proj_mat),1,max)>0]
PTSD_ICs = rownames(PTSD_proj_mat)[apply(abs(PTSD_proj_mat),1,max)>0]
TNP_ICs = rownames(TNP_proj_mat)[apply(abs(TNP_proj_mat),1,max)>0]

ICs=paste0("IC",1:10)
IC_groups = data.frame(IC=ICs, GAD = ifelse(ICs%in%GAD_ICs,"GAD",""), HC = ifelse(ICs%in%HC_ICs,"HC",""),
                       MDD = ifelse(ICs%in%MDD_ICs,"MDD",""), PTSD = ifelse(ICs%in%PTSD_ICs,"PTSD",""),
                       TNP = ifelse(ICs%in%TNP_ICs,"TNP",""))

# Now lets do the sources
find_questions <- function(df_included, threshold_perc, max_components=NA){
  # A function to find the questions that contribute mostly to each IC
  
  # choose the specified number of components
  if (is.na(max_components)){
    max_components = nrow(df_included)
  }
  df_included = df_included[1:max_components,]  
  # IC_list is the list of questions included in each IC
  IC_list = list()
  for (i in 1:max_components){
    threshold = as.numeric(quantile(df_included[i,],threshold_perc))
    df_source = as.numeric(df_included[i,])
    
    # get the colnames of questions which pass the threshold
    IC_list[[i]] = colnames(df_included[i,][df_source > threshold])
  }
  return(IC_list)
}


find_q_percentages <-function(df1,df2,Factor, Threshold=0.5){
  #A Function to find the amount of similarity between ICs in terms of the included questions
  
  # create an empty matrix, and change its names
  Sources_mat_combined = matrix(0,nrow = length(df1),ncol = length(df2))
  dimnames(Sources_mat_combined) = list(paste0("IC",1:length(df1)), paste0("IC",1:length(df2)))
  names(dimnames(Sources_mat_combined)) = c("All",Factor)
  
  # Calculate the percentages for each IC in both data frames
  for (i in 1:length(df1)){
    percs = sapply(1:length(df2), function(x) round(length(df2[[x]][df1[[i]] %in% df2[[x]]])/length(df2[[x]]),3))
    Sources_mat_combined[i,] = percs
  }
  Sources_mat_combined[Sources_mat_combined<Threshold]=0
  return(Sources_mat_combined)
}

All_sources_matr = find_questions(sources_all,0.8,10)
GAD_sources_matr = find_questions(sources_GAD,0.8,10)
HC_sources_matr = find_questions(sources_HC,0.8,10)
MDD_sources_matr = find_questions(sources_MDD,0.8,10)
PTSD_sources_matr = find_questions(sources_PTSD,0.8,10)
TNP_sources_matr = find_questions(sources_TNP,0.8,10)



GAD_intersection_perc = find_q_percentages(All_sources_matr, GAD_sources_matr, "GAD",0.5)
HC_intersection_perc = find_q_percentages(All_sources_matr, HC_sources_matr, "HC",0.5)
MDD_intersection_perc = find_q_percentages(All_sources_matr, MDD_sources_matr, "MDD",0.5)
PTSD_intersection_perc = find_q_percentages(All_sources_matr, PTSD_sources_matr, "PTSD",0.5)
TNP_intersection_perc = find_q_percentages(All_sources_matr, TNP_sources_matr, "TNP",0.5)


HC_sources_ICs = rownames(HC_intersection_perc)[apply(abs(HC_intersection_perc),1,max)>0]
GAD_sources_ICs = rownames(GAD_intersection_perc)[apply(abs(GAD_intersection_perc),1,max)>0]
MDD_sources_ICs = rownames(MDD_intersection_perc)[apply(abs(MDD_intersection_perc),1,max)>0]
PTSD_sources_ICs = rownames(PTSD_intersection_perc)[apply(abs(PTSD_intersection_perc),1,max)>0]
TNP_sources_ICs = rownames(TNP_intersection_perc)[apply(abs(TNP_intersection_perc),1,max)>0]


ICs=paste0("IC",1:10)
IC_source_groups = data.frame(IC=ICs, GAD = ifelse(ICs%in%GAD_sources_ICs,"GAD",""), HC = ifelse(ICs%in%HC_sources_ICs,"HC",""),
                       MDD = ifelse(ICs%in%MDD_sources_ICs,"MDD",""), PTSD = ifelse(ICs%in%PTSD_sources_ICs,"PTSD",""),
                       TNP = ifelse(ICs%in%TNP_sources_ICs,"TNP",""))



# I will do a correlation test

source_cor <- function(df_1, df_2, Factor, max_components_1, max_components_2, estimate_threshold){
  if (is.na(max_components_1)){
    max_components_1 = nrow(df_1)
    max_components_2 = nrow(df_2)
  }
  df_1 = df_1[1:max_components_1,]
  df_2 = df_2[1:max_components_2,]
  
  Sources_cor = matrix(0,nrow = max_components_1,ncol = max_components_2)
  dimnames(Sources_cor) = list(paste0("IC",1:max_components_1), paste0("IC",1:max_components_2))
  names(dimnames(Sources_cor)) = c("All",Factor)
    
  for (i in 1:max_components_1){
    threshold = 0.05/max_components_2
    estimates = sapply(1:max_components_2, function(x) cor.test(as.numeric(df_1[i,]),as.numeric(df_2[x,]))$estimate)
    p_values = sapply(1:max_components_2, function(x) cor.test(as.numeric(df_1[i,]),as.numeric(df_2[x,]))$p.value)
    estimates[p_values>threshold | abs(estimates)<estimate_threshold] = 0
    Sources_cor[i,] = estimates
  }
  return(Sources_cor)
}


est_threshold = 0.6
HC_sources_Cor = source_cor(sources_all, sources_HC, "HC", 10, 10, est_threshold)
GAD_sources_Cor = source_cor(sources_all, sources_GAD, "GAD", 10, 10, est_threshold)
MDD_sources_Cor = source_cor(sources_all, sources_MDD, "MDD", 10, 10, est_threshold)
PTSD_sources_Cor = source_cor(sources_all, sources_PTSD, "PTSD", 10, 10, est_threshold)
TNP_sources_Cor = source_cor(sources_all, sources_TNP, "TNP", 10, 10, est_threshold)


HC_sources_ICs_all = rownames(HC_sources_Cor)[apply(abs(HC_sources_Cor),1,max)>0]
GAD_sources_ICs_all = rownames(GAD_sources_Cor)[apply(abs(GAD_sources_Cor),1,max)>0]
MDD_sources_ICs_all = rownames(MDD_sources_Cor)[apply(abs(MDD_sources_Cor),1,max)>0]
PTSD_sources_ICs_all = rownames(PTSD_sources_Cor)[apply(abs(PTSD_sources_Cor),1,max)>0]
TNP_sources_ICs_all = rownames(TNP_sources_Cor)[apply(abs(TNP_sources_Cor),1,max)>0]


# now find the ICs in the each sources df that 
HC_sources_ICs = sapply(HC_sources_ICs_all,function(item) c(item,colnames(HC_sources_Cor)[abs(HC_sources_Cor[item,])>0]))
GAD_sources_ICs = sapply(GAD_sources_ICs_all,function(item) c(item,colnames(GAD_sources_Cor)[abs(GAD_sources_Cor[item,])>0]))
MDD_sources_ICs = sapply(MDD_sources_ICs_all,function(item) c(item,colnames(MDD_sources_Cor)[abs(MDD_sources_Cor[item,])>0]))
PTSD_sources_ICs = sapply(PTSD_sources_ICs_all,function(item) c(item,colnames(PTSD_sources_Cor)[abs(PTSD_sources_Cor[item,])>0]))
TNP_sources_ICs = sapply(TNP_sources_ICs_all,function(item) c(item,colnames(TNP_sources_Cor)[abs(TNP_sources_Cor[item,])>0]))

ICs=paste0("IC",1:10)
IC_source_correlations = data.frame(IC=ICs, GAD = ifelse(ICs%in%GAD_sources_ICs,"GAD",""), HC = ifelse(ICs%in%HC_sources_ICs,"HC",""),
                       MDD = ifelse(ICs%in%MDD_sources_ICs,"MDD",""), PTSD = ifelse(ICs%in%PTSD_sources_ICs,"PTSD",""),
                       TNP = ifelse(ICs%in%TNP_sources_ICs,"TNP",""))



all_sources = data.frame(Question = melt(sources_HC[1:10,])$variable, IC_all = rep(paste0("IC",1:10),100), All = melt(sources_all[1:10,])$value, HC = melt(sources_HC[1:10,])$value, 
                         GAD = melt(sources_GAD[1:10,])$value, MDD = melt(sources_MDD[1:10,])$value, PTSD = melt(sources_PTSD[1:10,])$value, TNP = melt(sources_TNP[1:10,])$value)


all_sources_melted = melt(all_sources, id.vars = c("Question","IC_all"), value.name = "Source", variable.name = "Group")
all_sources_melted$IC_group = NA
shuffle_ICs <- function(Sources_IC, Factor){
  if (length(Sources_IC)>0){
    for (i in 1:ncol(Sources_IC)){
      all_sources_melted$IC_group[all_sources_melted$Group==Factor&all_sources_melted$IC_all== Sources_IC[1,i]] = Sources_IC[2,i]
      all_sources_melted$Sources_group[all_sources_melted$Group==Factor&all_sources_melted$IC_all== Sources_IC[1,i]] = all_sources_melted$Source[all_sources_melted$Group==Factor&all_sources_melted$IC_all== Sources_IC[2,i]]
    }
  }
  return(all_sources_melted)
}

all_sources_melted = shuffle_ICs(HC_sources_ICs,"HC")
all_sources_melted = shuffle_ICs(GAD_sources_ICs,"GAD")
all_sources_melted = shuffle_ICs(PTSD_sources_ICs,"PTSD")
all_sources_melted = shuffle_ICs(TNP_sources_ICs,"TNP")
all_sources_melted = shuffle_ICs(MDD_sources_ICs,"MDD")
all_sources_melted$Sources_group[all_sources_melted$Group == "All"] = all_sources_melted$Source[all_sources_melted$Group == "All"]

g1 = ggplot(data = all_sources_melted, aes(x=Question, y= Sources_group, group =Group))+
    geom_line()+
    facet_grid(Group~IC_all)+
    geom_text(aes(x= 50,y=10,label = IC_group))

# use sources from one data frame to reconstruct original data

```


```{r plot different types of reconstructions}
library (ggplot2)
library(reshape2)
library(dplyr)
general_info = py$projections_all[,1:8]
for (i in 1:8){
  general_info[,i][general_info[,i]=="NA"]=NA
}
general_info = as.data.frame(apply(general_info,2,as.factor))
general_info$ID = factor(general_info$ID, levels = general_info$ID)

prepare_data_list <- function(df_list){
  # A function to prepare projections data frames
  for(i in 1:length(df_list)){
    df_list[[i]] = cbind(general_info,df_list[[i]])
    colnames(df_list[[i]])=c(colnames(df_list[[i]])[1:8],paste0("Q",1:100))
  }
  
  df_list_melted = sapply(1:length(df_list),function(i) melt(df_list[[i]], variable.name = "Question", value.name = "Reconstruction"),simplify = FALSE)
  df_list_melted = bind_rows(df_list_melted)
  df_list_melted$IC = factor(rep(paste0("IC",1:10),each = 182200),levels = paste0("IC",1:10))
  data_reco_mean = bind_rows(lapply(levels(df_list_melted$Question),function(item) SMeans(df_list_melted[df_list_melted$Question==item,],DV = "Reconstruction", IVs = c("Diagnosis","IC"), GroupBy = "Diagnosis")))
  data_reco_mean$Question = rep(levels(df_list_melted$Question),each = 50)
  data_reco_mean$IC = factor(data_reco_mean$IC, levels = paste0("IC",1:10))
  return (list(df_list_melted,data_reco_mean))
}

data_reco_all_list = prepare_data_list(py$data_reco_all_list)
data_reco_hc_list = prepare_data_list(py$data_reco_hc_list)
data_reco_mdd_list = prepare_data_list(py$data_reco_mdd_list)
data_reco_gad_list = prepare_data_list(py$data_reco_gad_list)
data_reco_ptsd_list = prepare_data_list(py$data_reco_ptsd_list)
data_reco_tnp_list =prepare_data_list( py$data_reco_tnp_list)

data_reco_all = data_reco_all_list[1]
data_reco_hc = data_reco_hc_list[1]
data_reco_mdd = data_reco_mdd_list[1]
data_reco_gad = data_reco_gad_list[1]
data_reco_ptsd = data_reco_ptsd_list[1]
data_reco_tnp = data_reco_tnp_list[1]

data_reco_all = data_reco_all_list[1]
data_reco_hc = data_reco_hc_list[1]
data_reco_mdd = data_reco_mdd_list[1]
data_reco_gad = data_reco_gad_list[1]
data_reco_ptsd = data_reco_ptsd_list[1]
data_reco_tnp = data_reco_tnp_list[1]

g_all = ggplot(data_reco_all, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)

g_hc = ggplot(data_reco_hc, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)


g_mdd = ggplot(data_reco_mdd, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)


g_gad = ggplot(data_reco_gad, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)


g_ptsd = ggplot(data_reco_ptsd, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)

g_tnp = ggplot(data_reco_tnp, aes(x= Question, y = Reconstruction, group = Groups, fill = Groups))+
  geom_point(color = "black", shape = 21)+
  TypicalTheme+
  scale_y_continuous(limits = c(0,0.4))+
  scale_fill_manual(values = c("#4EA3DF","#6cBE58","#C33E3B","#808CA3","#B9B0AB"))+
  facet_wrap(~IC)
```